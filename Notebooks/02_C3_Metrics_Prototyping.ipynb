{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook runs on a Python3 kernel\n",
    "No kernel changes required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics on the C3 AI Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C3 Metrics are data used to quickly and scalably aggregate and transform raw data into time series. Metrics can be implemented in the platform or defined on the fly in a Python notebook or environment console. The list of transforms that can be used to define metrics is described in the `ExpressionEngineFunction` type.\n",
    "\n",
    "C3 Metrics can be of 2 different types:\n",
    "- `SimpleMetric` (including `TsDeclMetric`), which is for defining a way to access data and transform it\n",
    "- `CompoundMetric` to do mathematical operations on other metrics\n",
    "\n",
    "Each new metric becomes a new building block for more complex metrics. In the future if that building block changes (to fix a bug for example), all the metrics that depend on it will be modified automatically. That behavior makes metrics easy to define, maintain and share across your organization.\n",
    "\n",
    "Data Scientists use metrics to explore the data and create features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** The cells below contain generic working code. You can edit the existing code or add additional cells as you'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T08:49:17.156243Z",
     "start_time": "2022-04-07T08:49:16.858070Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 1000\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Use This Space for \"CHALLENGE: Write Helper Functions for Metric Visualization\" \n",
    "    \n",
    "#### Skip this now and come back at the end of Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T08:53:34.616789Z",
     "start_time": "2022-04-07T08:53:34.612753Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FUTURE CHALLENGE - Skip for now\n",
    "Implement helper function that takes an EvalMetricsSpec\n",
    "and returns an appropriately formatted dataframe\n",
    "(See demo video for example functionality)\n",
    "'''\n",
    "\n",
    "def spec_to_emr_to_df(source_type: object, spec: object, on_the_fly: bool, overrideMetrics: list):\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T08:53:34.790037Z",
     "start_time": "2022-04-07T08:53:34.785878Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FUTURE CHALLENGE - Skip for now\n",
    "Implement helper function that takes in a dataframe, ids and expressions\n",
    "and plots them using the plotting tool of your choice.\n",
    "(See demo video for example of functionality using matplotlib)\n",
    "'''\n",
    "def plot_metrics(df, ids, expressions):\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Evaluating Metrics Already Provisioned on the Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following block of code allows you to list all the Metrics available on a specified Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:59:58.393252Z",
     "start_time": "2022-04-07T06:59:58.345250Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(c3.MyType.listMetrics().toJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:25.301830Z",
     "start_time": "2022-04-06T11:42:25.273455Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### REMINDER:  `evalMetrics` or `evalMetricsWithMetadata`\n",
    "\n",
    "* `evalMetrics`: to evaluate metrics already defined (i.e. provisioned) in C3 AI Suite environment\n",
    "* `evalMetricsWithMetadata`: to evaluate metrics defined on the fly or already in C3 AI Suite. If you do this, you will need to pass in a second argument to this function that will be a list of the metrics that do not yet exist in a C3 Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create EvalMetricsSpec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:25.823590Z",
     "start_time": "2022-04-06T11:42:25.819706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_spec = c3.EvalMetricsSpec(\n",
    "            ids = [\"UniqueId1\"],\n",
    "            expressions = [\"MyMetric\"],\n",
    "            start = \"2018-01-01\",\n",
    "            end = \"2021-12-01\",\n",
    "            interval = \"DAY\" \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Retrieve EvalMetricsResult:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:26.246556Z",
     "start_time": "2022-04-06T11:42:26.156612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evalMetricsResult = c3.Building.evalMetrics(spec=my_spec)\n",
    "evalMetricsResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Convert to pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:26.494599Z",
     "start_time": "2022-04-06T11:42:26.488286Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = c3.EvalMetricsResult.toPandas(evalMetricsResult)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:26.661870Z",
     "start_time": "2022-04-06T11:42:26.655693Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add source and timestamp column to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:27.003956Z",
     "start_time": "2022-04-06T11:42:26.996825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['source'] = df.index.str.split('_').str[0]\n",
    "df['timestamp'] = pd.to_datetime(df.index.str.split('_').str[1],format=\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:27.363240Z",
     "start_time": "2022-04-06T11:42:27.356382Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['source']=='UniqueId1'].plot(x='timestamp',y='MyExpression')\n",
    "# df[df['source']=='id2'].plot(x='timestamp',y='MyExpression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Use This Space for \"CHALLENGE: Visualize Metrics\" \n",
    "    \n",
    "    Add additional cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Prototyping and Evaluating Simple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:28.950616Z",
     "start_time": "2022-04-06T11:42:28.909729Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldMetrics = pd.DataFrame(c3.Building.listMetrics().toJson())\n",
    "bldMetrics\n",
    "# bldMetrics[bldMetrics['id'] == \"AverageTemperature_Building\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define Simple Metric that you want to prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:34.771177Z",
     "start_time": "2022-04-06T11:42:29.307203Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_metric = c3.SimpleMetric(id = \"MyMetric_MySrcType\",\n",
    "                            name = \"MyMetric\",\n",
    "                            description = \"description of the metric\",\n",
    "                            srcType = \"MySrcType\",\n",
    "                            path = \"MyPath\",\n",
    "                            expression = \"MyExpression\"\n",
    "                           )\n",
    "            \n",
    "my_metric.toJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create EvalMetricsSpec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:34.775258Z",
     "start_time": "2022-04-06T11:42:34.772675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_spec = c3.EvalMetricsSpec(\n",
    "            ids = [\"UniqueId1\", \"UniqueId2\"],\n",
    "            expressions = [\"MyMetric\"],\n",
    "            start = \"2018-01-01\",\n",
    "            end = \"2021-01-01\",\n",
    "            interval = \"DAY\" \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get EvalMetricsResult:\n",
    "\n",
    "**Note**: We use `evalMetricsWithMetadata` while prototyping metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:34.801575Z",
     "start_time": "2022-04-06T11:42:34.776760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evalMetricsResult = c3.MyEntityType.evalMetricsWithMetadata(spec=my_spec,\n",
    "                                                      overrideMetrics=[my_metric])\n",
    "evalMetricsResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Convert to pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:35.073190Z",
     "start_time": "2022-04-06T11:42:35.066911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert EvalMetricsResult to Pandas DataFrame\n",
    "df = c3.EvalMetricsResult.toPandas(result=evalMetricsResult)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add source and timestamp column to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:36.514597Z",
     "start_time": "2022-04-06T11:42:36.507616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Post process dataframe to add 'source' and 'timestamp' column\n",
    "df['source'] = df.index.str.split('_').str[0]\n",
    "df['timestamp'] = pd.to_datetime(df.index.str.split('_').str[1],format=\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:37.736177Z",
     "start_time": "2022-04-06T11:42:37.729344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df['source']=='UniqueId1'].plot(x='timestamp',y='MyExpression')\n",
    "df[df['source']=='UniqueId2'].plot(x='timestamp',y='MyExpression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that you've prototyped and tested your metric, you need to create a json file for it (or add it to an existing json file) and provision it to the server so it will be available to run later or for use in compound metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:42:42.201987Z",
     "start_time": "2022-04-06T11:42:42.200079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # You have 2 options to get your metric into a file -- comment in and use whichever one you prefer!\n",
    "\n",
    "# # will print out the metric code directly, copy and paste in VS Code\n",
    "# # recommended if you have an existing file and you simply want to copy and paste to add this metric in there\n",
    "# my_metric.toJson() \n",
    "\n",
    "\n",
    "# # will write the metric to a json file named myMetric.json\n",
    "# # recommended for one-off metrics or for Compound Metrics (in Section 4)\n",
    "# import json\n",
    "# with open('myMetric.json', 'w') as f:\n",
    "#   json.dump(my_metric.toJson(), f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Use This Space for \"CHALLENGE: Prototype Simple Metrics in Jupyter\" \n",
    "    \n",
    "    Add additional cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Prototyping and Evaluating Simple `TSDecl` Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Optional: compare data structures of SmartBulbMeasurement and PowerGridStatusSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:05.572620Z",
     "start_time": "2022-04-06T11:43:05.570749Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(c3.SmartBulbMeasurement.fetch(spec={\n",
    "#     \"filter\": \"parent == 'SBMS_serialNo_SMBLB1'\",\n",
    "#     \"order\": \"ascending(start)\"\n",
    "# }).objs.toJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:05.745345Z",
     "start_time": "2022-04-06T11:43:05.743523Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(c3.PowerGridStatusSet.fetch(spec={\n",
    "#     \"order\": \"ascending(timestamp)\",\n",
    "#     \"filter\": \"parent.id == 'bld1'\"\n",
    "# }).objs.toJson())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "View the documentation and fields on a TSDecl metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:06.173829Z",
     "start_time": "2022-04-06T11:43:06.058385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(c3.TSDecl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define TSDecl Metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:06.396586Z",
     "start_time": "2022-04-06T11:43:06.373148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "myTsDeclMetric = c3.SimpleMetric(id = \"MyTsDeclMetric_MySrcType\",\n",
    "                                 name = \"MyTsDeclMetric\",\n",
    "                                 description = \"description of the metric\",\n",
    "                                 srcType = \"MySrcType\",\n",
    "                                 path = \"MyPath\",\n",
    "                                 tsDecl = c3.TSDecl(data = \"data\",\n",
    "                                                   value = \"value\",\n",
    "                                                   treatment = \"TREATMENT\",\n",
    "                                                   start = \"timestampField\"))\n",
    "\n",
    "myTsDeclMetric.toJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create EvalMetricsSpec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:06.709231Z",
     "start_time": "2022-04-06T11:43:06.706591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_tsdecl_spec = c3.EvalMetricsSpec(ids = [\"UniqueId1\", \"UniqueId2\", \"UniqueId3\"],\n",
    "                                    expressions = [\"MyTsDeclMetric\"],\n",
    "                                    start = \"2018-01-01\",\n",
    "                                    end = \"2021-01-01\",\n",
    "                                    interval = \"DAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:06.885406Z",
     "start_time": "2022-04-06T11:43:06.883601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # steps to visualize:\n",
    "#   -- pass spec into EvalMetrics(WithMetadata) to be evaluated\n",
    "#   -- convert EvalMetricsResult objs into pandas df\n",
    "#   -- post-process df\n",
    "#   -- plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Go back to the top of the notebook to complete \"CHALLENGE: Write Helper Functions for Metric Visualization\"\n",
    "\n",
    "    Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use helper function to generate an appropriately formatted dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:07.468231Z",
     "start_time": "2022-04-06T11:43:07.461929Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO - \n",
    "# You have to implement this method in the code-block shown at the top of this notebook\n",
    "\n",
    "df = spec_to_emr_to_df(source_type=c3.Apartment,\n",
    "                       spec=my_tsdecl_spec,\n",
    "                       on_the_fly=True,\n",
    "                       overrideMetrics=[myTsDeclMetric])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the plotting helper function, generate plots for different ids for the Metric you prototyped above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T11:43:09.026551Z",
     "start_time": "2022-04-06T11:43:09.020406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO - \n",
    "# You have to implement this method in the code-block shown at the top of this notebook\n",
    "\n",
    "plot_metrics(df, [\"UniqueId1\", \"UniqueId2\", \"UniqueId3\"], [\"PowerGridStatus\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Use This Space for \"CHALLENGE: Prototype TSDecl Simple Metrics in Jupyter\" \n",
    "    \n",
    "    Add additional cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Prototyping and Evaluating Compound Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T12:08:51.987681Z",
     "start_time": "2022-04-06T12:08:51.957316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smblbMetrics = pd.DataFrame(c3.SmartBulb.listMetrics().toJson())\n",
    "smblbMetrics[smblbMetrics['name'] == 'Status'][['type', 'name', 'expression', 'id', 'path']]\n",
    "# smblbMetrics[['type', 'name', 'expression', 'id', 'path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T10:08:37.291100Z",
     "start_time": "2022-04-06T10:08:36.684049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(c3.ExpressionEngineFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define Compound Metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T12:20:17.769078Z",
     "start_time": "2022-04-06T12:20:17.764595Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_compound_metric = c3.CompoundMetric(id = \"MyCompoundMetric\",\n",
    "                                name = \"MyCompoundMetric\",\n",
    "                                description = \"description of my compound metric\",\n",
    "                                expression = \"MyExpression\")\n",
    "my_compound_metric.toJson()\n",
    "\n",
    "\n",
    "# my_compound_metric2 = c3.CompoundMetric(id = \"MyCompoundMetric\",\n",
    "#                                 name = \"MyCompoundMetric\",\n",
    "#                                 description = \"description of my compound metric\",\n",
    "#                                 expression = \"MyExpression\")\n",
    "# my_compound_metric2.toJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the helper functions defined above, retrieve data for your prototyped compound metric and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T12:20:20.126974Z",
     "start_time": "2022-04-06T12:20:19.540018Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "myType = c3.SmartBulb\n",
    "ids = [\"UniqueId1\", \"UniqueId2\"] #ids for the objects to evaluate the metric\n",
    "expressions = [\"MyCompoundMetric\"]\n",
    "start = \"2018-10-01\"\n",
    "end = \"2019-12-31\"\n",
    "interval = \"DAY\"\n",
    "\n",
    "#define EvalMetricsSpec\n",
    "my_spec = c3.EvalMetricsSpec(ids = ids,\n",
    "                             expressions = expressions,\n",
    "                             start = start,\n",
    "                             end = end,\n",
    "                             interval = interval)\n",
    "\n",
    "# retrieve appropriately formatted dataframe\n",
    "# ensure that you have defined these methods\n",
    "df = spec_to_emr_to_df(source_type=myType, spec=my_spec, on_the_fly=False, overrideMetrics=[None])\n",
    "\n",
    "plot_metrics(df, ids, expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Use This Space for \"CHALLENGE: Prototype Compound Metrics in Jupyter\" \n",
    "    \n",
    "    Add additional cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. EDA and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Examine the metrics already available on the SmartBulb Type for use as features, mask, and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T10:01:52.018544Z",
     "start_time": "2022-04-07T10:01:51.026856Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(c3.SmartBulb.listMetrics().toJson())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Use This Space for \"CHALLENGE: Organize Target, Mask, and Features\" \n",
    "    \n",
    "    Add additional cells as needed.\n",
    "    You may wish to use markdown cells to jot down the notes that you make as part of this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T10:02:57.405726Z",
     "start_time": "2022-04-07T10:02:56.616941Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize metrics to use as target and mask\n",
    "\n",
    "myType = c3.SmartBulb\n",
    "ids = [\"UniqueId1\", \"UniqueId2\", \"UniqueId3\"] \n",
    "expressions = [\"MyCompoundMetric\"]\n",
    "start = \"2018-01-01\"\n",
    "end = \"2019-12-31\"\n",
    "interval = \"DAY\"\n",
    "\n",
    "my_spec = c3.EvalMetricsSpec(ids = ids,\n",
    "                             expressions = expressions,\n",
    "                             start = start,\n",
    "                             end = end,\n",
    "                             interval = interval)\n",
    "\n",
    "df = spec_to_emr_to_df(source_type=myType, spec=my_spec, on_the_fly=False, overrideMetrics=[None])\n",
    "\n",
    "plot_metrics(df, ids, expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T10:04:07.472446Z",
     "start_time": "2022-04-07T10:04:06.980254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize metrics to use as features\n",
    "\n",
    "myType = c3.SmartBulb\n",
    "ids = [\"UniqueId1\", \"UniqueId2\", \"UniqueId3\"] \n",
    "expressions = [\"MyCompoundMetric\"]\n",
    "start = \"2018-01-01\"\n",
    "end = \"2019-12-31\"\n",
    "interval = \"DAY\"\n",
    "\n",
    "my_spec = c3.EvalMetricsSpec(ids = ids,\n",
    "                             expressions = expressions,\n",
    "                             start = start,\n",
    "                             end = end,\n",
    "                             interval = interval)\n",
    "\n",
    "df = spec_to_emr_to_df(source_type=myType, spec=my_spec, on_the_fly=False, overrideMetrics=[None])\n",
    "\n",
    "plot_metrics(df, ids, expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OPTIONAL ADDITIONAL EXERCISES: Getting Comfortable with Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As a data scientist working on the C3 AI Suite, you will most likely work extensively with metrics, creating complex expressions and combining multiple metrics during Data Exploration and Feature Engineering. These cells allow you to practice creating metrics using a wide variety of ExpressionEngineFunctions and putting them together. Feel free to complete as many or as few of these as you'd like, but we highly recommend you work through at least a few of them to get the hang of using `help(c3.ExpressionEngineFunction)` and finding the functions you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(c3.ExpressionEngineFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are pieces missing from the following metric definitions (signified with ???); use what you've learned so far and the available expression engine functions to complete them. You can then use the functions you defined earlier in the notebook to plot the results and see what they look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note that we've given you most of the code block for these metrics**; what this section is intended to do is to get you comfortable with looking up ExpressionEngineFunctions to create the \"expression\" field of your metric and playing around with the evaluation specifications to see how they affect your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a start_date and an end_date that you can use for all of the EvalMetricSpecs below based on the dataset\n",
    "# you are using\n",
    "\n",
    "start_date = ???\n",
    "end_date = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Practice with SimpleMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Simple Metric 1**\n",
    "\n",
    "> Define a metric that returns the average value of temperature across time and the average across space\n",
    "\n",
    "> Evaluate the metric with interval = \"DAY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m1 = c3.SimpleMetric(\n",
    "    id = \"m1_SmartBulb\",\n",
    "    name = \"m1\",\n",
    "    srcType = \"???\",\n",
    "    path = \"???\",\n",
    "    expression = \"???\"\n",
    ")\n",
    "\n",
    "spec1 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m1\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = \"???\"\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 2\n",
    "\n",
    "> Define a metric that returns the **average** value of **temperature** across time and **no aggregation** across space\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2 = c3.SimpleMetric(\n",
    "    id = \"m2_SmartBulb\",\n",
    "    name = \"m2\",\n",
    "    srcType = \"???\",\n",
    "    path = \"???\",\n",
    "    expression = \"???\"\n",
    ")\n",
    "\n",
    "spec2 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m2\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = \"???\"\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Simple Metric 3**\n",
    "\n",
    "> Define a metric that returns the **average** value of the **temperature** across time and the **average** across space\n",
    "\n",
    "> Evaluate the metric with **interval = \"HOUR\"**\n",
    "\n",
    "Comparing this result with the result of **simple metric 1**. Why does one look spiky and one look smoothed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m3 = c3.SimpleMetric(\n",
    "    id = \"m3_SmartBulb\",\n",
    "    name = \"m3\",\n",
    "    srcType = \"???\",\n",
    "    path = \"???\",\n",
    "    expression = \"???\"\n",
    ")\n",
    "\n",
    "spec3 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m3\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = \"???\"\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 4\n",
    "\n",
    "> Define a metric that returns the **min** value of **temperature** across time and the **average** across space\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m4 = c3.SimpleMetric(\n",
    "    id = \"m4_SmartBulb\",\n",
    "    name = \"m4\",\n",
    "    srcType = \"???\",\n",
    "    path = \"???\",\n",
    "    expression = \"???\"\n",
    ")\n",
    "\n",
    "spec4 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m4\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = \"???\"\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 5\n",
    "\n",
    "> Define a metric that returns the **average** value of **power** across time and the **average** across space on **un-normalized** data\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m5 = c3.SimpleMetric(\n",
    "    id = \"m5_SmartBulb\",\n",
    "    name = \"m5\",\n",
    "    srcType = \"???\",\n",
    "    path = \"???\",\n",
    "    expression = \"???\"\n",
    ")\n",
    "\n",
    "spec5 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m5\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = \"???\"\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### TSDecl Simple Metrics\n",
    "\n",
    "##### Remember that TSDecl metrics are used for \"statusy-eventy-data\" (as one C3 engineer memorably expressed it). This means non-continuous, non-normalized data (such as earthquakes, or sporadic power outages). You are effectively using the first half of the metric code (the TsDecl spec) to force this data into a neat, useable time series that can be evaluated in a metric along with the rest of your standardized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 6 (TS Decl)\n",
    "\n",
    "> Define a metric that returns the **value** for the **gridStatusSet** event\n",
    "\n",
    "> **Normalize** on the fly to get the **average** across time\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**\n",
    "\n",
    "Hint:\n",
    "\n",
    "> Fetch on the **PowerGridStatusSet** type to understand the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(c3.PowerGridStatus.fetch().objs.toJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "td6 = c3.TSDecl(\n",
    "    data = \"gridStatusSet\",\n",
    "    start = ???,\n",
    "    treatment = ???,\n",
    "    value = ???\n",
    ")\n",
    "\n",
    "m6 = c3.SimpleMetric(\n",
    "    id = \"m6_Building\",\n",
    "    name = \"m6\",\n",
    "    srcType = ???,\n",
    "    tsDecl = td6\n",
    ")\n",
    "\n",
    "spec6 = c3.EvalMetricsSpec(\n",
    "    ids = [\"bld1\"],\n",
    "    expressions = [\"m6\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 7 (TS Decl)\n",
    "\n",
    "> Define a metric that returns the **value** for the **gridStatusSet** event\n",
    "\n",
    "> **Normalize** on the fly and use `PREVIOUS` as the treatment\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**\n",
    "\n",
    "Compare this result with the previous one; does it make sense? Remember, when data is missing, the value will still be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "td7 = c3.TSDecl(\n",
    "    data = \"gridStatusSet\",\n",
    "    start = ???,\n",
    "    treatment = ???,\n",
    "    value = ???\n",
    ")\n",
    "\n",
    "m7 = c3.SimpleMetric(\n",
    "    id = \"m7_Building\",\n",
    "    name = \"m7\",\n",
    "    srcType = ???,\n",
    "    tsDecl = td7\n",
    ")\n",
    "\n",
    "spec7 = c3.EvalMetricsSpec(\n",
    "    ids = [\"bld1\"],\n",
    "    expressions = [\"m7\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 8 (TSDecl)\n",
    "\n",
    "> Define a metric that returns **100** if value for the **gridStatusSet** event is greater than 0.5, otherwise return **50**. Note that the \"value\" field for TSDecl metrics can be used much like the \"expression\" field in a Simple or Compound Metric.\n",
    "\n",
    "> If there is a missing value, we want to impute with the **previous** value\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "td8 = c3.TSDecl(\n",
    "    data = \"gridStatusSet\",\n",
    "    start = ???,\n",
    "    treatment = ???,\n",
    "    value = ???\n",
    ")\n",
    "\n",
    "m8 = c3.SimpleMetric(\n",
    "    id = \"m8_Building\",\n",
    "    name = \"m8\",\n",
    "    srcType = ???,\n",
    "    tsDecl = td8\n",
    ")\n",
    "\n",
    "spec8 = c3.EvalMetricsSpec(\n",
    "    ids = [\"bld1\"],\n",
    "    expressions = [\"m8\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 9 (TSDecl)\n",
    "\n",
    "> Define a metric that returns the **maximum value** for the **gridStatusSet** for an Apartment.\n",
    "\n",
    "> Use a **normalization treatment** on the fly to get the average.\n",
    "\n",
    "> If data is missing, impute with the number **15** (use the \"transform\" field).\n",
    "\n",
    "> Try evaluating the metric with different intervals.\n",
    "\n",
    "\n",
    "Hint: Run `c3ShowType(ExpressionEngineFunction)` and checkout `fillMissing()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "td9 = c3.TSDecl(\n",
    "    data = \"gridStatusSet\",\n",
    "    start = ???,\n",
    "    treatment = ???,\n",
    "    value = ???,\n",
    "    transform = ???\n",
    ")\n",
    "\n",
    "m9 = c3.SimpleMetric(\n",
    "    id = \"m9_Apartment\",\n",
    "    name = \"m9\",\n",
    "    srcType = ???,\n",
    "    tsDecl = td9\n",
    ")\n",
    "\n",
    "spec9 = c3.EvalMetricsSpec(\n",
    "    ids = [\"apt1\"],\n",
    "    expressions = [\"m9\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 10 (TSDecl)\n",
    "\n",
    "> Define a metric that returns the **value** for the **gridStatusSet** event\n",
    "\n",
    "> If data is missing, impute with the number **15**\n",
    "\n",
    "> Use **'PREVIOUS'** as treatment\n",
    "\n",
    "> Evaluate the metric with **interval = \"DAY\"**\n",
    "\n",
    "Comprehension Check: Which missing data is imputed because of the `PREVIOUS` treatment and which is imputed because of the `fillMissing()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "td10 = c3.TSDecl(\n",
    "    data = \"gridStatusSet\",\n",
    "    start = ???,\n",
    "    treatment = ???,\n",
    "    value = ???,\n",
    "    transform = ???\n",
    ")\n",
    "\n",
    "m10 = c3.SimpleMetric(\n",
    "    id = \"m10_Building\",\n",
    "    name = \"m10\",\n",
    "    srcType = ???,\n",
    "    tsDecl = td10\n",
    ")\n",
    "\n",
    "spec10 = c3.EvalMetricsSpec(\n",
    "    ids = [\"bld1\"],\n",
    "    expressions = [\"m10\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Simple Metric 11\n",
    "\n",
    "> Define a metric that returns **1** if the **lowercase of the first character of manufacturer name is 'g'**, and **0 otherwise**\n",
    "\n",
    "Hint: Using `c3ShowType(ExpressionEngineFunction)`, check out `startsWith()` and `lowerCase()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m11 = c3.SimpleMetric(\n",
    "    id = \"m11_SmartBulb\",\n",
    "    name = \"m11\",\n",
    "    srcType = ???,\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec11 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB10\"],\n",
    "    expressions = [\"m11\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Practice with CompoundMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 1\n",
    "> Define a compound metric that returns a smoothed version of AverageTemperature - meaning a sliding window of average from values of the simple metric results. Start the window as 20 values before the current one. Set the window size to be 20\n",
    "\n",
    "> Evaluate the metric with interval: 'HOUR' and again with interval: 'DAY'.\n",
    "\n",
    "Hint: Use `c3ShowType(ExpressionEngineFunction)` to get more information on the window() function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m12 = c3.CompoundMetric(\n",
    "    id = \"m12\",\n",
    "    name = \"m12\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec12a = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m12\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)\n",
    "\n",
    "\n",
    "spec12b = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m12\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 2\n",
    "\n",
    "> Define a compound metric that returns a smoothed version of AverageTemperature *that forces the metric evaluation to use 20 hours as the window* - meaning a sliding window of average from the previous **20 hours**.\n",
    "\n",
    "> Use \"HOUR\" as the interval in the metric spec. What happens? Can you still get the average over 20 hours even though the metric spec is evaluating at an \"HOUR\" interval?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m13 = c3.CompoundMetric(\n",
    "    id = \"m13\",\n",
    "    name = \"m13\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec13 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m13\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Compound Metric 3\n",
    "\n",
    "> Define a compound metric that returns a smoothed version of `AverageTemperature` with a sliding window of the average from 2 **days** before to the current one\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'HOUR'\"** Then evaluate it using **\"interval == 'DAY'\"**\n",
    "\n",
    "What is happening here? How are the two intervals (the forced `eval()` and the metric spec interval) interacting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m14 = c3.CompoundMetric(\n",
    "    id = \"m14\",\n",
    "    name = \"m14\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec14a = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m14\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)\n",
    "\n",
    "\n",
    "spec14b = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m14\"],\n",
    "    start = \"2011-01-01\",\n",
    "    end = \"2011-03-01\",\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 4\n",
    "\n",
    "> Define a compound metric that returns the **sum** of temperature since the beginning of time\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'DAY'\"**\n",
    "\n",
    "Pay attention to the values. The first sum shouldn't start at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m15 = c3.CompoundMetric(\n",
    "    id = \"m15\",\n",
    "    name = \"m15\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec15 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m15\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 5\n",
    "\n",
    "> Define a compound metric that returns **1** if the **average temperature** is **greater or equal than 80**, and 0 otherwise\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'DAY'\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m16 = c3.CompoundMetric(\n",
    "    id = \"m16\",\n",
    "    name = \"m16\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec16 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m16\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 6\n",
    "\n",
    "> Use the compound metric 5 created just above to define a compound metric that returns the **sum** of **temperature since the beginning of time**, and **resets** the sum if a temperature point is **greater or equal than 80**\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'DAY'\"**\n",
    "\n",
    "Hint: not sure how to reset? Use `c3ShowType(ExpressionEngineFunction)` to get more information on the `rolling()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m17 = c3.CompoundMetric(\n",
    "    id = \"m17\",\n",
    "    name = \"m17\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "\n",
    "spec17 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m17\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 7\n",
    "\n",
    "> Use the same compound metric 5 to define a compound metric that returns the **number of days** since a **temperature point** was **greater or equal than 80**\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'DAY'\"**\n",
    "\n",
    "Hint: `c3ShowType(ExpressionEngineFunction)` and look for `identity()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m18 = c3.CompoundMetric(\n",
    "    id = \"m18\",\n",
    "    name = \"m18\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "\n",
    "spec18 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m18\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 8 + 9\n",
    "\n",
    "> Define a compound metric that returns **1** if the **average power** is **<=4**, and returns 0 otherwise.\n",
    "\n",
    "> Use **this compound metric** as well as **compound metric 5** to define a compound metric that returns **1** if the **average tempeature** is **>=80** and the **average power** is **<=4**, and returns (-1) **otherwise**\n",
    "\n",
    "> Evaluate the metric with **\"interval == 'DAY'\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compound metric that returns 1 if average power is <= 4, otherwise 0\n",
    "\n",
    "m19 = c3.CompoundMetric(\n",
    "    id = \"m19\",\n",
    "    name = \"m19\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "# Compound metric that returns 1 if average temp is >=80 and average power is <=4, otherwise -1\n",
    "\n",
    "m20 = c3.CompoundMetric(\n",
    "    id = \"m20\",\n",
    "    name = \"m20\",\n",
    "    expression = ???\n",
    ")\n",
    "\n",
    "spec20 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"m20\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compound Metric 10\n",
    "\n",
    "> Define a compound metric called `StandardDeviationWattsPreviousWeek` that returns the **standard deviation** of the `AveragePower` simple metric over the **past week.**\n",
    "\n",
    "> Evaluate the metric using **\"interval == 'DAY'\"**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m21 = c3.CompoundMetric(id = \"StandardDeviationWattsPreviousWeek\",\n",
    "                        name = \"StandardDeviationWattsPreviousWeek\",\n",
    "                        expression = ???)\n",
    "\n",
    "spec21 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"StandardDeviationWattsPreviousWeek\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Persist the metrics you want to keep in the code for your application, being careful to put it in the right folder (convert to JSONs and put them in the appropriate folder). Then, povision your changes; when provisioning has finished, confirm that the metrics were added by listing all the metrics on SmartBulb using `c3Grid(SmartBulb.listMetrics())` in the console or by running the cell below.\n",
    "\n",
    "> Hint: Ensure that when you create your json file that it is in the seed folder subdirectory named either `'SimpleMetric'` or `'CompoundMetric'`. The filename is not important for the purposes of the platform, but by convention and for better organization and file management for you, we suggest either:\n",
    "    - naming the file containing a single metric **MetricName.json** \n",
    "        or\n",
    "    - putting all metrics for one SourceType together into a single json and naming it **TypeName.json**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(c3.SmartBulb.listMetrics().toJson())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once you've confirmed that your metrics appear on the Type, then test one or more of them below using the function you created (which, as you remember, should work for both protyped or provisioned metrics!).\n",
    "  \n",
    "Note what is different between the code you need to run prototyped metrics and when you run them after they've been provisioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DON'T NEED THIS ANYMORE AFTER PROVISIONING \n",
    "#m00 = c3.CompoundMetric(id = \"MetricID\",\n",
    "#                         name = \"MetricName\",\n",
    "#                         expression = \"some(expression(engine*functions)))\")\n",
    "\n",
    "\n",
    "# this part stays the same. The system will find the metric by name \n",
    "spec24 = c3.EvalMetricsSpec(\n",
    "    ids = [\"SMBLB1\"],\n",
    "    expressions = [\"MyMetricName\"],\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    interval = ???\n",
    ")\n",
    "\n",
    "spec_to_emr_to_df(???)\n",
    "plot_metrics(???)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Optional Bonus: helper GUI to explore and prototype metrics\n",
    "\n",
    "Note that this tool automatically pulls all fields and pathways on all Types in the application data model! This means that there may be many theoretically possible pathways that the tool picks up, but which you don't need/that make no sense to use in metrics here.\n",
    "\n",
    "**NOTE** You may have to install additional packages such as ipywidgets if you are running this notebook locally; if you are working on the training environment, you should be able to run this with the standard Python3 kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T21:09:30.322602Z",
     "start_time": "2021-10-18T21:09:29.291995Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c3.DSVisualizationHelper.metricDesignerGui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure to SYNC your notebook to the server, then CLOSE AND HALT this notebook when you leave.\n",
    "To sync: go to the File menu, Save and Checkpoint your notebook, and then select \"Upload Notebook to C3.ai\", or select the notebook in the tree view (check the box) and hit the \"Sync\" button."
   ]
  }
 ],
 "metadata": {
  "has_local_update": true,
  "is_local": true,
  "is_remote": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "last_sync_time": "2022-04-11T16:42:32.709445"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
